import torch
from transformers import AutoTokenizer
import os
import sys

from model import SoomgoServiceClassifier, get_device, load_model
from predict import preprocess_request_text, preprocess_chat_text, predict_suitability, format_input_text

def print_header(title):
    """프린트 헤더 형식화"""
    print("\n" + "="*60)
    print(f"{title}".center(60))
    print("="*60)

def test_custom_input():
    """사용자가 직접 입력한 요청서와 채팅으로 테스트"""
    print_header("직접 입력 테스트")
    
    print("\n요청서 텍스트를 입력하세요 ([Q][A] 형식):")
    print("예시: [Q] 어떤 서비스를 원하시나요? [A] 입주청소")
    print("입력 종료는 빈 줄에서 Enter를 누르세요.")
    
    request_lines = []
    while True:
        line = input()
        if not line:
            break
        request_lines.append(line)
    
    request_text = "\n".join(request_lines)
    
    print("\n채팅 내용을 입력하세요 (고객: 또는 고수: 형식):")
    print("예시: 고객: 청소 문의드립니다")
    print("입력 종료는 빈 줄에서 Enter를 누르세요.")
    
    chat_lines = []
    while True:
        line = input()
        if not line:
            break
        chat_lines.append(line)
    
    chat_text = "\n".join(chat_lines)
    
    if not request_text.strip():
        print("요청서 텍스트가 필요합니다. 예제 테스트로 넘어갑니다.")
        return False
        
    # 입력 텍스트 포맷팅
    formatted_request = format_input_text(request_text)
    formatted_chat = format_input_text(chat_text) if chat_text else ""
    
    return formatted_request, formatted_chat

def test_examples():
    """미리 정의된 예제로 테스트"""
    examples = [
        {
            "name": "입주청소 (높은 확률로 적합)",
            "request": "[Q] 어떤 서비스를 원하시나요? [A] 입주청소\n[Q] 어떤 건물인가요? [A] 아파트\n[Q] 방 개수를 선택해주세요. [A] 2개\n[Q] 화장실 개수를 선택해주세요. [A] 1개\n[Q] 베란다 개수를 선택해주세요. [A] 1개",
            "chat": "고객: 안녕하세요, 입주청소 문의드립니다.\n고수: 네, 안녕하세요. 어떤 크기의 집인가요?\n고객: 24평 아파트입니다."
        },
        {
            "name": "이사청소 (높은 확률로 적합)",
            "request": "[Q] 어떤 서비스를 원하시나요? [A] 이사청소\n[Q] 어떤 건물인가요? [A] 빌라/연립/다세대\n[Q] 방 개수를 선택해주세요. [A] 2개\n[Q] 화장실 개수를 선택해주세요. [A] 1개",
            "chat": "고객: 이사 나가기 전에 청소 필요해요\n고수: 어느 지역이신지요?\n고객: 서울 강남구입니다."
        },
        {
            "name": "거주청소 (중간 확률로 적합)",
            "request": "[Q] 어떤 서비스를 원하시나요? [A] 거주청소\n[Q] 어떤 부분의 청소를 원하시나요? [A] 화장실\n[Q] 화장실 개수를 선택해주세요. [A] 2개",
            "chat": "고객: 집 화장실 청소 도움 필요해요\n고수: 네, 어떤 부분이 특히 신경쓰이시나요?\n고객: 타일 사이 곰팡이 제거 필요합니다."
        },
        {
            "name": "부적합 (다른 서비스)",
            "request": "[Q] 어떤 서비스를 원하시나요? [A] 기타: 방역 소독\n[Q] 어떤 건물인가요? [A] 아파트\n[Q] 방 개수를 선택해주세요. [A] 3개",
            "chat": "고객: 바퀴벌레 방역 문의드립니다.\n고수: 어떤 해충 때문에 소독이 필요하신가요?\n고객: 주로 바퀴벌레입니다."
        },
        {
            "name": "부적합 (이사 서비스)",
            "request": "[Q] 어떤 서비스를 원하시나요? [A] 기타: 이사\n[Q] 어떤 건물인가요? [A] 아파트\n[Q] 방 개수를 선택해주세요. [A] 청소할 필요 없음",
            "chat": "고객: 이삿짐 옮기는데 얼마인가요?\n고수: 저희는 청소 업체입니다.\n고객: 실례했습니다."
        }
    ]
    
    return examples

def main():
    """메인 함수"""
    # 디바이스 설정
    device = get_device()
    print(f"사용 디바이스: {device}")
    
    # 모델 및 토크나이저 로드
    model_path = "unified_output/model.pt"
    tokenizer_path = "unified_output/tokenizer"
    
    if not os.path.exists(model_path):
        print(f"오류: 모델 파일을 찾을 수 없습니다: {model_path}")
        return
    
    print_header("모델 로딩")
    model, tokenizer = load_model(model_path, tokenizer_path, device)
    print("모델 로딩 완료!")
    
    # 테스트 모드 선택
    print_header("테스트 모드 선택")
    print("1: 직접 입력으로 테스트")
    print("2: 예제로 테스트")
    
    choice = input("\n선택 (1 또는 2): ").strip()
    
    if choice == "1":
        # 사용자 직접 입력 테스트
        result = test_custom_input()
        
        if result:
            request_text, chat_text = result
            print_header("입력 내용 확인")
            print("\n요청서 내용:")
            print(request_text)
            print("\n채팅 내용:")
            print(chat_text if chat_text else "(채팅 없음)")
            
            print_header("예측 결과")
            score, service_type_info = predict_suitability(request_text, chat_text, model, tokenizer, device)
            
            print(f"\n'이사/입주청소업체' 서비스 적합도: {score:.2f}%")
            print(f"판단: {'적합함' if score > 50 else '적합하지 않음'}")
            print(f"예측 서비스 유형: {service_type_info['predicted_type']} (신뢰도: {service_type_info['confidence']:.2f}%)")
            print("서비스 유형별 확률:")
            for service_type, prob in service_type_info['all_probabilities'].items():
                print(f"  - {service_type}: {prob:.2f}%")
    
    else:
        # 예제 테스트
        examples = test_examples()
        
        print_header("예제 테스트 결과")
        
        for i, example in enumerate(examples, 1):
            print(f"\n예제 {i}: {example['name']}")
            print("-" * 40)
            
            # 입력 텍스트 포맷팅
            request_text = format_input_text(example['request'])
            chat_text = format_input_text(example['chat'])
            
            # 예측
            score, service_type_info = predict_suitability(request_text, chat_text, model, tokenizer, device)
            
            print(f"서비스 적합도: {score:.2f}%")
            print(f"판단: {'적합함' if score > 50 else '적합하지 않음'}")
            print(f"예측 서비스 유형: {service_type_info['predicted_type']} (신뢰도: {service_type_info['confidence']:.2f}%)")
            
            # 간략하게 서비스 유형별 확률 표시
            sorted_probs = sorted(
                service_type_info['all_probabilities'].items(), 
                key=lambda x: x[1], 
                reverse=True
            )
            for service_type, prob in sorted_probs:
                print(f"  - {service_type}: {prob:.2f}%")
                
            print()  # 빈 줄 추가
    
    print_header("테스트 완료")
    print("학습된 모델의 예측 테스트가 완료되었습니다.")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n테스트가 중단되었습니다.")
        sys.exit(0)
    except Exception as e:
        print(f"\n오류 발생: {e}")
        sys.exit(1) 